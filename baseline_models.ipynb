{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f5750af",
   "metadata": {},
   "source": [
    "# Baseline Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c081bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_Classifiers.py\n",
    "import os, json, time, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold, train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from joblib import dump\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Optional imports\n",
    "try:\n",
    "    from skopt import BayesSearchCV\n",
    "    from skopt.space import Real, Integer, Categorical\n",
    "    HAVE_BAYES = True\n",
    "except Exception:\n",
    "    HAVE_BAYES = False\n",
    "    print(\"skopt not available, skipping related tests.\")\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAVE_XGB = True\n",
    "except Exception:\n",
    "    HAVE_XGB = False\n",
    "    print(\"XGBoost not available, skipping related tests.\")\n",
    "\n",
    "# GPU-specific imports\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from skorch import NeuralNetClassifier\n",
    "    HAVE_TORCH = True\n",
    "except Exception:\n",
    "    HAVE_TORCH = False\n",
    "    print(\"PyTorch/skorch not available, falling back to sklearn MLP.\")\n",
    "\n",
    "try:\n",
    "    from cuml.ensemble import RandomForestClassifier as cuRF\n",
    "    from cuml.neighbors import KNeighborsClassifier as cuKNN\n",
    "    from cuml.svm import SVC as cuSVC\n",
    "    import cupy as cp\n",
    "    HAVE_CUML = True\n",
    "except Exception:\n",
    "    HAVE_CUML = False\n",
    "    print(\"RAPIDS cuML not available, falling back to sklearn models.\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Global logger instance\n",
    "logger = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25f22df",
   "metadata": {},
   "source": [
    "## LOGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3db2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger(log_dir=\"logs\"):\n",
    "    \"\"\"\n",
    "    Set up logging to both file and console with timestamps\n",
    "    \"\"\"\n",
    "    global logger\n",
    "    \n",
    "    # Create logs directory\n",
    "    log_path = Path(log_dir)\n",
    "    log_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create timestamped log file\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_file = log_path / f\"baseline_models_{timestamp}.log\"\n",
    "    \n",
    "    # Configure logger\n",
    "    logger = logging.getLogger(\"baseline_models\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    # Remove existing handlers to avoid duplicates\n",
    "    logger.handlers.clear()\n",
    "    \n",
    "    # File handler with detailed formatting\n",
    "    file_handler = logging.FileHandler(log_file, mode='w', encoding='utf-8')\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "    file_formatter = logging.Formatter(\n",
    "        '%(asctime)s - %(levelname)s - %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "    file_handler.setFormatter(file_formatter)\n",
    "    \n",
    "    # Console handler with simpler formatting\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "    console_formatter = logging.Formatter('%(message)s')\n",
    "    console_handler.setFormatter(console_formatter)\n",
    "    \n",
    "    # Add handlers\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "    logger.info(f\"Logging initialized. Log file: {log_file}\")\n",
    "    return logger\n",
    "\n",
    "def log_print(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    Custom print function that prints to console and logs to file\n",
    "    Maintains print() API compatibility\n",
    "    \"\"\"\n",
    "    global logger\n",
    "    \n",
    "    # Convert all arguments to strings and join them\n",
    "    message = ' '.join(str(arg) for arg in args)\n",
    "    \n",
    "    # Handle special print kwargs\n",
    "    sep = kwargs.get('sep', ' ')\n",
    "    end = kwargs.get('end', '\\n')\n",
    "    \n",
    "    if len(args) > 1:\n",
    "        message = sep.join(str(arg) for arg in args)\n",
    "    \n",
    "    # Print to console (logger's console handler will do this)\n",
    "    if logger:\n",
    "        # Log without the newline (logger adds its own)\n",
    "        logger.info(message.rstrip('\\n'))\n",
    "    else:\n",
    "        # Fallback to regular print if logger not initialized\n",
    "        print(*args, **kwargs)\n",
    "\n",
    "# Replace the built-in print with our logging version\n",
    "print = log_print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84250f76",
   "metadata": {},
   "source": [
    "## DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c352fdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Function to rename columns by removing leading or trailing spaces\n",
    "    def rename_columns(df):\n",
    "        df.columns = df.columns.str.strip()  # Remove leading/trailing spaces\n",
    "        return df \n",
    "\n",
    "    print(\"Loading data...\")\n",
    "    csv_paths = glob.glob(\"data/train/*.csv\")  # LDAP, MSSQL, NetBIOS, SYN, UDP, UDPlag\n",
    "    df_list = []\n",
    "    for path in tqdm(csv_paths):\n",
    "        temp = pd.read_csv(path)\n",
    "        temp = rename_columns(temp)  # Clean column names\n",
    "        temp[\"Scenario\"] = Path(path).stem  # optional for reference\n",
    "        df_list.append(temp)\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Drop irrelevant identifiers\n",
    "    drop_cols = [\n",
    "        \"Unnamed: 0\", \"Flow ID\", \"Source IP\", \"Destination IP\",\n",
    "        \"SimillarHTTP\", \"Inbound\"\n",
    "    ]\n",
    "    df = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "    # Handle infinities\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # Parse timestamps and build groups\n",
    "    df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"], errors=\"coerce\")\n",
    "    groups = df[\"Timestamp\"].dt.floor(\"min\")  # group by minute\n",
    "    # if we ever want to change the granulairity:\n",
    "    # groups = df[\"Timestamp\"].dt.floor(\"h\")   # hour\n",
    "    # groups = df[\"Timestamp\"].dt.floor(\"s\")   # second\n",
    "    # groups = df[\"Timestamp\"].dt.floor(\"5min\")  # 5-minute windows\n",
    "    # Separate features and target\n",
    "    \n",
    "    X = df.drop(columns=[\"Label\"])\n",
    "    y = df[\"Label\"]\n",
    "\n",
    "    # Encode target\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    \n",
    "    print(f\"Data loaded: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "\n",
    "    return X, y, groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d3591c",
   "metadata": {},
   "source": [
    "## UTILITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e637423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_device_info():\n",
    "    try:\n",
    "        import torch\n",
    "        print(\"[GPU] PyTorch CUDA available:\", torch.cuda.is_available())\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"       CUDA device:\", torch.cuda.get_device_name(0))\n",
    "            print(\"       CUDA version:\", torch.version.cuda)\n",
    "    except Exception:\n",
    "        print(\"[GPU] PyTorch not installed\")\n",
    "\n",
    "    try:\n",
    "        import xgboost as xgb\n",
    "        print(\"[GPU] XGBoost version:\", xgb.__version__)\n",
    "    except Exception:\n",
    "        print(\"[GPU] XGBoost not installed\")\n",
    "    \n",
    "    try:\n",
    "        import cuml\n",
    "        print(\"[GPU] RAPIDS cuML version:\", cuml.__version__)\n",
    "        import cupy as cp\n",
    "        print(\"       CuPy available:\", cp.cuda.is_available())\n",
    "    except Exception:\n",
    "        print(\"[GPU] RAPIDS cuML not installed\")\n",
    "\n",
    "def make_output_dir(base=\"runs\"):\n",
    "    ts = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    outdir = Path(base) / f\"models/classif_{ts}\"\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    return outdir\n",
    "\n",
    "def bin_for_stratification(y, n_bins=10):\n",
    "    # bins for approximate stratification on a continuous target\n",
    "    quantiles = np.linspace(0, 1, n_bins + 1)\n",
    "    edges = np.unique(np.quantile(y, quantiles))\n",
    "    y_binned = np.digitize(y, edges[1:-1], right=True)\n",
    "    return y_binned\n",
    "\n",
    "def get_cv(y, groups=None, n_splits=5, seed=RANDOM_STATE):\n",
    "    if groups is not None:\n",
    "        return GroupKFold(n_splits=n_splits)\n",
    "    else:\n",
    "        y_bins = bin_for_stratification(y, n_bins=10)\n",
    "        return StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed), y_bins\n",
    "\n",
    "def primary_scorer():\n",
    "    return \"f1_micro\"\n",
    "\n",
    "def scoring_dict():\n",
    "    return {\n",
    "        \"F1_micro\": make_scorer(f1_score, average=\"micro\"),\n",
    "        \"Precision_micro\": make_scorer(precision_score, average=\"micro\"),\n",
    "        \"Recall_micro\": make_scorer(recall_score, average=\"micro\"),\n",
    "        \"Accuracy\": make_scorer(accuracy_score),\n",
    "    }\n",
    "\n",
    "def numeric_preprocessor(scaler_type: str | None = \"standard\", impute: bool = True):\n",
    "    steps = []\n",
    "    if impute:\n",
    "        steps.append((\"impute\", SimpleImputer(strategy=\"median\")))\n",
    "    if scaler_type:\n",
    "        if scaler_type == \"standard\":\n",
    "            steps.append((\"scale\", StandardScaler()))\n",
    "        elif scaler_type == \"minmax\":\n",
    "            steps.append((\"scale\", MinMaxScaler()))\n",
    "        elif scaler_type == \"robust\":\n",
    "            steps.append((\"scale\", RobustScaler()))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown scaler_type: {scaler_type}\")\n",
    "    return Pipeline(steps)\n",
    "\n",
    "def build_selector(k):\n",
    "    return SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "\n",
    "def k_grid_from_dim(n_features):\n",
    "    # progressive MI sizes; ensure uniqueness and <= n_features\n",
    "    candidates = [8, 16, 32, 48, 64, n_features]\n",
    "    ks = sorted(list({min(k, n_features) for k in candidates if k <= n_features}))\n",
    "    return ks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac57b76",
   "metadata": {},
   "source": [
    "## MODEL SPACES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d428802c",
   "metadata": {},
   "source": [
    "## Reduced Param Search Space \n",
    "\n",
    "Minimal versions for testing correctness of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b9a9936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_space():\n",
    "    if HAVE_BAYES:\n",
    "        return [\n",
    "            (\"LogisticRegression\",\n",
    "             LogisticRegression(\n",
    "                 multi_class=\"multinomial\",\n",
    "                 solver=\"saga\",\n",
    "                 penalty=\"elasticnet\",\n",
    "                 max_iter=2000,\n",
    "                 random_state=RANDOM_STATE\n",
    "             ),\n",
    "             {\n",
    "                 \"model__C\": Real(0.1, 10.0, prior=\"log-uniform\"),\n",
    "                 \"model__l1_ratio\": Real(0.0, 1.0),\n",
    "                 \"model__class_weight\": Categorical([None, \"balanced\"]),\n",
    "             })\n",
    "        ]\n",
    "    else:\n",
    "        return [\n",
    "            (\"LogisticRegression\",\n",
    "             LogisticRegression(\n",
    "                 multi_class=\"multinomial\",\n",
    "                 solver=\"saga\",\n",
    "                 penalty=\"elasticnet\",\n",
    "                 max_iter=2000,\n",
    "                 random_state=RANDOM_STATE\n",
    "             ),\n",
    "             {\n",
    "                 \"model__C\": [0.1, 1.0, 10.0],\n",
    "                 \"model__l1_ratio\": [0.0, 0.5, 1.0],\n",
    "                 \"model__class_weight\": [None, \"balanced\"],\n",
    "             })\n",
    "        ]\n",
    "\n",
    "def rf_space():\n",
    "    if HAVE_BAYES:\n",
    "        return {\n",
    "            \"model__n_estimators\": Integer(50, 200),\n",
    "            \"model__max_depth\": Integer(3, 10),\n",
    "            \"model__min_samples_split\": Integer(2, 5),\n",
    "            \"model__min_samples_leaf\": Integer(1, 3),\n",
    "            \"model__max_features\": Categorical([\"sqrt\", \"log2\"]),\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"model__n_estimators\": [50, 100, 200],\n",
    "            \"model__max_depth\": [None, 5, 10],\n",
    "            \"model__min_samples_split\": [2, 5],\n",
    "            \"model__min_samples_leaf\": [1, 2],\n",
    "            \"model__max_features\": [\"sqrt\", \"log2\"],\n",
    "        }\n",
    "\n",
    "def xgb_space():\n",
    "    if HAVE_BAYES:\n",
    "        return {\n",
    "            \"model__n_estimators\": Integer(50, 200),\n",
    "            \"model__max_depth\": Integer(3, 6),\n",
    "            \"model__learning_rate\": Real(0.01, 0.3, prior=\"log-uniform\"),\n",
    "            \"model__subsample\": Real(0.8, 1.0),\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"model__n_estimators\": [50, 100, 200],\n",
    "            \"model__max_depth\": [3, 5, 6],\n",
    "            \"model__learning_rate\": [0.01, 0.1, 0.3],\n",
    "            \"model__subsample\": [0.8, 1.0],\n",
    "        }\n",
    "\n",
    "def knn_space():\n",
    "    if HAVE_BAYES:\n",
    "        return {\n",
    "            \"model__n_neighbors\": Integer(3, 15),\n",
    "            \"model__weights\": Categorical([\"uniform\", \"distance\"]),\n",
    "            \"model__p\": Integer(1, 2),\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"model__n_neighbors\": [3, 5, 7, 11, 15],\n",
    "            \"model__weights\": [\"uniform\", \"distance\"],\n",
    "            \"model__p\": [1, 2],\n",
    "        }\n",
    "\n",
    "def mlp_space():\n",
    "    if HAVE_BAYES:\n",
    "        return {\n",
    "            \"model__hidden_layer_sizes\": Categorical([(64,), (128,)]),\n",
    "            \"model__activation\": Categorical([\"relu\", \"tanh\"]),\n",
    "            \"model__alpha\": Real(1e-4, 1e-2, prior=\"log-uniform\"),\n",
    "            \"model__learning_rate_init\": Real(1e-3, 1e-2, prior=\"log-uniform\"),\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"model__hidden_layer_sizes\": [(64,), (128,)],\n",
    "            \"model__activation\": [\"relu\", \"tanh\"],\n",
    "            \"model__alpha\": [1e-4, 1e-3, 1e-2],\n",
    "            \"model__learning_rate_init\": [1e-3, 5e-3, 1e-2],\n",
    "        }\n",
    "    \n",
    "def svc_space_classifier():\n",
    "    if HAVE_BAYES:\n",
    "        # Bayesian search space (scikit-optimize)\n",
    "        return {\n",
    "            \"model__kernel\": Categorical([\"rbf\"]),\n",
    "            # \"model__C\": Real(1e-3, 1e2, prior=\"log-uniform\"),\n",
    "            # gamma is relevant for 'rbf'; it's ignored for 'linear' (safe to include)\n",
    "            \"model__gamma\": Categorical([\"scale\", \"auto\"]),\n",
    "            \"model__class_weight\": Categorical([\"balanced\"]),\n",
    "        }\n",
    "    else:\n",
    "        # Randomized search grid\n",
    "        return {\n",
    "            \"model__kernel\": [\"rbf\"],\n",
    "            \"model__C\": np.logspace(-3, 2, 3),  # 1e-3, 1e-2, 1e-1, 1, 10, 100 \n",
    "            \"model__gamma\": [\"auto\"],  # used when kernel='rbf'\n",
    "            \"model__class_weight\": [\"balanced\"],\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb2ee8d",
   "metadata": {},
   "source": [
    "## Full Param Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b172e176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_space():\n",
    "    if HAVE_BAYES:\n",
    "        return [\n",
    "            (\"LogisticRegression\",\n",
    "             LogisticRegression(\n",
    "                 multi_class=\"multinomial\",\n",
    "                 solver=\"saga\",\n",
    "                 penalty=\"elasticnet\",\n",
    "                 max_iter=2000,\n",
    "                 random_state=RANDOM_STATE\n",
    "             ),\n",
    "             {\n",
    "                 \"model__C\": Real(0.1, 10.0, prior=\"log-uniform\"),\n",
    "                 \"model__l1_ratio\": Real(0.0, 1.0),\n",
    "                 \"model__class_weight\": Categorical([None, \"balanced\"]),\n",
    "             })\n",
    "        ]\n",
    "    else:\n",
    "        return [\n",
    "            (\"LogisticRegression\",\n",
    "             LogisticRegression(\n",
    "                 multi_class=\"multinomial\",\n",
    "                 solver=\"saga\",\n",
    "                 penalty=\"elasticnet\",\n",
    "                 max_iter=2000,\n",
    "                 random_state=RANDOM_STATE\n",
    "             ),\n",
    "             {\n",
    "                 \"model__C\": [0.1, 1.0, 10.0],\n",
    "                 \"model__l1_ratio\": [0.0, 0.5, 1.0],\n",
    "                 \"model__class_weight\": [None, \"balanced\"],\n",
    "             })\n",
    "        ]\n",
    "\n",
    "def rf_space():\n",
    "    if HAVE_BAYES:\n",
    "        return {\n",
    "            \"model__n_estimators\": Integer(50, 200),\n",
    "            \"model__max_depth\": Integer(3, 10),\n",
    "            \"model__min_samples_split\": Integer(2, 5),\n",
    "            \"model__min_samples_leaf\": Integer(1, 3),\n",
    "            \"model__max_features\": Categorical([\"sqrt\", \"log2\"]),\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"model__n_estimators\": [50, 100, 200],\n",
    "            \"model__max_depth\": [None, 5, 10],\n",
    "            \"model__min_samples_split\": [2, 5],\n",
    "            \"model__min_samples_leaf\": [1, 2],\n",
    "            \"model__max_features\": [\"sqrt\", \"log2\"],\n",
    "        }\n",
    "\n",
    "def rf_space_gpu():\n",
    "    \"\"\"Random Forest search space for cuML GPU version\"\"\"\n",
    "    if HAVE_BAYES:\n",
    "        return {\n",
    "            \"model__n_estimators\": Integer(50, 200),\n",
    "            \"model__max_depth\": Integer(3, 10),\n",
    "            \"model__min_samples_split\": Integer(2, 5),\n",
    "            \"model__max_features\": Real(0.5, 1.0),  # cuML uses float instead of string\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"model__n_estimators\": [50, 100, 200],\n",
    "            \"model__max_depth\": [5, 10, 16],\n",
    "            \"model__min_samples_split\": [2, 5],\n",
    "            \"model__max_features\": [0.5, 0.7, 1.0],\n",
    "        }\n",
    "\n",
    "def xgb_space():\n",
    "    if HAVE_BAYES:\n",
    "        return {\n",
    "            \"model__n_estimators\": Integer(50, 200),\n",
    "            \"model__max_depth\": Integer(3, 6),\n",
    "            \"model__learning_rate\": Real(0.01, 0.3, prior=\"log-uniform\"),\n",
    "            \"model__subsample\": Real(0.8, 1.0),\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"model__n_estimators\": [50, 100, 200],\n",
    "            \"model__max_depth\": [3, 5, 6],\n",
    "            \"model__learning_rate\": [0.01, 0.1, 0.3],\n",
    "            \"model__subsample\": [0.8, 1.0],\n",
    "        }\n",
    "\n",
    "def knn_space():\n",
    "    if HAVE_BAYES:\n",
    "        return {\n",
    "            \"model__n_neighbors\": Integer(3, 15),\n",
    "            \"model__weights\": Categorical([\"uniform\", \"distance\"]),\n",
    "            \"model__p\": Integer(1, 2),\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"model__n_neighbors\": [3, 5, 7, 11, 15],\n",
    "            \"model__weights\": [\"uniform\", \"distance\"],\n",
    "            \"model__p\": [1, 2],\n",
    "        }\n",
    "\n",
    "def knn_space_gpu():\n",
    "    \"\"\"KNN search space for cuML GPU version\"\"\"\n",
    "    if HAVE_BAYES:\n",
    "        return {\n",
    "            \"model__n_neighbors\": Integer(3, 15),\n",
    "            \"model__weights\": Categorical([\"uniform\", \"distance\"]),\n",
    "            \"model__p\": Integer(1, 2),\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"model__n_neighbors\": [3, 5, 7, 11, 15],\n",
    "            \"model__weights\": [\"uniform\", \"distance\"],\n",
    "            \"model__p\": [1, 2],\n",
    "        }\n",
    "\n",
    "def mlp_space():\n",
    "    if HAVE_BAYES:\n",
    "        return {\n",
    "            \"model__hidden_layer_sizes\": Categorical([(64,), (128,)]),\n",
    "            \"model__activation\": Categorical([\"relu\", \"tanh\"]),\n",
    "            \"model__alpha\": Real(1e-4, 1e-2, prior=\"log-uniform\"),\n",
    "            \"model__learning_rate_init\": Real(1e-3, 1e-2, prior=\"log-uniform\"),\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"model__hidden_layer_sizes\": [(64,), (128,)],\n",
    "            \"model__activation\": [\"relu\", \"tanh\"],\n",
    "            \"model__alpha\": [1e-4, 1e-3, 1e-2],\n",
    "            \"model__learning_rate_init\": [1e-3, 5e-3, 1e-2],\n",
    "        }\n",
    "    \n",
    "def mlp_space_gpu(input_dim, num_classes):\n",
    "    \"\"\"MLP search space for PyTorch GPU version\"\"\"\n",
    "    if HAVE_BAYES:\n",
    "        return {\n",
    "            \"model__module__hidden_dim\": Categorical([64, 128, 256]),\n",
    "            \"model__module__dropout\": Real(0.1, 0.5),\n",
    "            \"model__lr\": Real(1e-4, 1e-2, prior=\"log-uniform\"),\n",
    "            \"model__batch_size\": Categorical([64, 128, 256]),\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"model__module__hidden_dim\": [64, 128, 256],\n",
    "            \"model__module__dropout\": [0.2, 0.3, 0.5],\n",
    "            \"model__lr\": [1e-4, 1e-3, 1e-2],\n",
    "            \"model__batch_size\": [64, 128, 256],\n",
    "        }\n",
    "\n",
    "def svc_space_classifier():\n",
    "    if HAVE_BAYES:\n",
    "        # Bayesian search space (scikit-optimize)\n",
    "        return {\n",
    "            \"model__kernel\": Categorical([\"rbf\"]),\n",
    "            # \"model__C\": Real(1e-3, 1e2, prior=\"log-uniform\"),\n",
    "            # gamma is relevant for 'rbf'; it's ignored for 'linear' (safe to include)\n",
    "            \"model__gamma\": Categorical([\"scale\", \"auto\"]),\n",
    "            \"model__class_weight\": Categorical([\"balanced\"]),\n",
    "        }\n",
    "    else:\n",
    "        # Randomized search grid\n",
    "        return {\n",
    "            \"model__kernel\": [\"rbf\"],\n",
    "            \"model__C\": np.logspace(-3, 2, 3),  # 1e-3, 1e-2, 1e-1, 1, 10, 100 \n",
    "            \"model__gamma\": [\"auto\"],  # used when kernel='rbf'\n",
    "            \"model__class_weight\": [\"balanced\"],\n",
    "        }\n",
    "\n",
    "def svc_space_gpu():\n",
    "    \"\"\"SVC search space for cuML GPU version\"\"\"\n",
    "    if HAVE_BAYES:\n",
    "        return {\n",
    "            \"model__kernel\": Categorical([\"rbf\"]),\n",
    "            \"model__C\": Real(0.1, 10.0, prior=\"log-uniform\"),\n",
    "            \"model__gamma\": Categorical([\"scale\", \"auto\"]),\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"model__kernel\": [\"rbf\"],\n",
    "            \"model__C\": [0.1, 1.0, 10.0],\n",
    "            \"model__gamma\": [\"scale\", \"auto\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a3bd5c",
   "metadata": {},
   "source": [
    "## BUILD & SEARCH HELPERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ee9895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch MLP for GPU\n",
    "class TorchMLP(nn.Module):\n",
    "    \"\"\"PyTorch MLP for GPU acceleration\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_classes=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim // 2)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.fc3 = nn.Linear(hidden_dim // 2, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def build_pipeline(model, scale_for_model, n_features, scaler_type=\"standard\", impute=True):\n",
    "    pre = numeric_preprocessor(scaler_type if scale_for_model else None, impute=impute)\n",
    "    selector = build_selector(k=n_features)  # tuned via search\n",
    "    return Pipeline([\n",
    "        (\"pre\", pre),\n",
    "        (\"select\", selector),\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "\n",
    "\n",
    "def print_memory_usage():\n",
    "    \"\"\"Print current memory usage\"\"\"\n",
    "    import psutil\n",
    "    process = psutil.Process()\n",
    "    mem_info = process.memory_info()\n",
    "    mem_mb = mem_info.rss / 1024 / 1024\n",
    "    print(f\"[Memory] Process RAM usage: {mem_mb:.2f} MB\")\n",
    "    \n",
    "    if HAVE_TORCH and torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024 / 1024\n",
    "        reserved = torch.cuda.memory_reserved() / 1024 / 1024\n",
    "        print(f\"[Memory] GPU allocated: {allocated:.2f} MB, reserved: {reserved:.2f} MB\")\n",
    "\n",
    "def cleanup_memory():\n",
    "    \"\"\"Force garbage collection and clear GPU cache\"\"\"\n",
    "    gc.collect()\n",
    "    \n",
    "    if HAVE_TORCH and torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    if HAVE_CUML:\n",
    "        try:\n",
    "            import cupy as cp\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "def search_cv_for_model(name, pipe, param_space, ks, X, y, groups, outdir, n_iter=60):\n",
    "    \"\"\"Search with explicit cleanup after fitting\"\"\"\n",
    "    # Add MI k to the search space\n",
    "    if HAVE_BAYES and isinstance(param_space, dict):\n",
    "        # Bayes: add k as a categorical dimension\n",
    "        from skopt.space import Categorical\n",
    "        param_space = dict(param_space)  # copy\n",
    "        param_space[\"select__k\"] = Categorical(ks)\n",
    "        # CV object\n",
    "        if groups is not None:\n",
    "            cv = GroupKFold(n_splits=5)\n",
    "            cv_groups = groups\n",
    "        else:\n",
    "            cv, y_bins = get_cv(y, groups=None, n_splits=5)\n",
    "            cv_groups = None\n",
    "        search = BayesSearchCV(\n",
    "            estimator=pipe,\n",
    "            search_spaces=param_space,\n",
    "            n_iter=n_iter,\n",
    "            cv=cv,\n",
    "            scoring=primary_scorer(),\n",
    "            n_jobs=-1,\n",
    "            random_state=RANDOM_STATE,\n",
    "            refit=True,\n",
    "            verbose=0,\n",
    "        )\n",
    "        search.fit(X, y, **({\"groups\": cv_groups} if cv_groups is not None else {}))\n",
    "    else:\n",
    "        # Randomized search\n",
    "        param_dist = {}\n",
    "        for k, v in param_space.items():\n",
    "            param_dist[k] = v\n",
    "        param_dist[\"select__k\"] = ks\n",
    "        if groups is not None:\n",
    "            cv = GroupKFold(n_splits=5)\n",
    "            cv_groups = groups\n",
    "        else:\n",
    "            cv, y_bins = get_cv(y, groups=None, n_splits=5)\n",
    "            cv_groups = None\n",
    "        search = RandomizedSearchCV(\n",
    "            estimator=pipe,\n",
    "            param_distributions=param_dist,\n",
    "            n_iter=min(n_iter, 100),\n",
    "            cv=cv,\n",
    "            scoring=primary_scorer(),\n",
    "            n_jobs=-1,\n",
    "            random_state=RANDOM_STATE,\n",
    "            refit=True,\n",
    "            verbose=0,\n",
    "        )\n",
    "        search.fit(X, y, **({\"groups\": cv_groups} if cv_groups is not None else {}))\n",
    "\n",
    "    # Extract best estimator before cleanup\n",
    "    best_estimator = search.best_estimator_\n",
    "    best_params = search.best_params_\n",
    "    cv_results = pd.DataFrame(search.cv_results_)\n",
    "    \n",
    "    # Delete search object to free memory\n",
    "    del search\n",
    "    if 'cv_groups' in locals():\n",
    "        del cv_groups\n",
    "    if 'cv' in locals():\n",
    "        del cv\n",
    "    gc.collect()\n",
    "\n",
    "    # Save best model and results\n",
    "    model_dir = outdir / f\"{name}\"\n",
    "    model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    dump(best_estimator, model_dir / \"best_model.joblib\")\n",
    "    cv_results.to_csv(model_dir / \"cv_results.csv\", index=False)\n",
    "    with open(model_dir / \"best_params.json\", \"w\") as f:\n",
    "        json.dump(best_params, f, indent=2)\n",
    "    \n",
    "    # Clean up results dataframe\n",
    "    del cv_results\n",
    "    gc.collect()\n",
    "\n",
    "    return best_estimator\n",
    "\n",
    "def evaluate_on_holdout(model, X_test, y_test, outdir, label):\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        \"Accuracy\": float(accuracy_score(y_test, preds)),\n",
    "        \"F1_micro\": float(f1_score(y_test, preds, average=\"micro\")),\n",
    "        \"Precision_micro\": float(precision_score(y_test, preds, average=\"micro\")),\n",
    "        \"Recall_micro\": float(recall_score(y_test, preds, average=\"micro\")),\n",
    "    }\n",
    "\n",
    "    # Save predictions\n",
    "    pd.DataFrame({\"y_true\": y_test, \"y_pred\": preds}).to_csv(outdir / f\"{label}_preds.csv\", index=False)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, cmap=\"Blues\", annot=False)\n",
    "    plt.title(f\"Confusion Matrix – {label}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outdir / f\"{label}_confusion_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Classification report (precision, recall, f1 per class)\n",
    "    report = classification_report(y_test, preds, output_dict=True)\n",
    "    pd.DataFrame(report).transpose().to_csv(outdir / f\"{label}_classification_report.csv\")\n",
    "\n",
    "    # Save metrics summary\n",
    "    with open(outdir / f\"{label}_metrics.json\", \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    \n",
    "    # Clean up intermediate variables\n",
    "    del preds, cm, report\n",
    "    gc.collect()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def create_comparison_visualizations(summary_df, outdir):\n",
    "    \"\"\"\n",
    "    Create comprehensive comparison charts for all baseline models\n",
    "    \"\"\"\n",
    "    print(f\"\\nGenerating comparison visualizations...\")\n",
    "    \n",
    "    # 1. Bar chart comparing all metrics across models\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    metrics = ['Accuracy', 'F1_micro', 'Precision_micro', 'Recall_micro']\n",
    "    \n",
    "    for idx, metric in enumerate(metrics):\n",
    "        ax = axes[idx // 2, idx % 2]\n",
    "        summary_df.plot(x='model', y=metric, kind='bar', ax=ax, legend=False, color='steelblue')\n",
    "        ax.set_title(f'{metric} Comparison', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Model', fontsize=12)\n",
    "        ax.set_ylabel(metric, fontsize=12)\n",
    "        ax.set_xticklabels(summary_df['model'], rotation=45, ha='right')\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(container, fmt='%.3f', padding=3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outdir / \"metrics_comparison_bars.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Radar/Spider chart for multi-metric comparison\n",
    "    from math import pi\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "    \n",
    "    angles = [n / len(metrics) * 2 * pi for n in range(len(metrics))]\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    ax.set_theta_offset(pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(metrics)\n",
    "    \n",
    "    for idx, row in summary_df.iterrows():\n",
    "        values = row[metrics].tolist()\n",
    "        values += values[:1]\n",
    "        ax.plot(angles, values, 'o-', linewidth=2, label=row['model'])\n",
    "        ax.fill(angles, values, alpha=0.15)\n",
    "    \n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "    ax.set_title('Multi-Metric Performance Comparison', size=16, fontweight='bold', pad=20)\n",
    "    ax.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outdir / \"metrics_radar_chart.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Heatmap of all metrics\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    metrics_matrix = summary_df.set_index('model')[metrics]\n",
    "    sns.heatmap(metrics_matrix, annot=True, fmt='.3f', cmap='YlGnBu', \n",
    "                cbar_kws={'label': 'Score'}, linewidths=0.5)\n",
    "    plt.title('Performance Metrics Heatmap', fontsize=16, fontweight='bold', pad=15)\n",
    "    plt.xlabel('Metrics', fontsize=12)\n",
    "    plt.ylabel('Models', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outdir / \"metrics_heatmap.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Model ranking visualization\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Calculate average rank for each model\n",
    "    ranks = summary_df[metrics].rank(ascending=False)\n",
    "    ranks['model'] = summary_df['model']\n",
    "    ranks['avg_rank'] = ranks[metrics].mean(axis=1)\n",
    "    ranks = ranks.sort_values('avg_rank')\n",
    "    \n",
    "    x_pos = np.arange(len(ranks))\n",
    "    bars = ax.barh(x_pos, ranks['avg_rank'], color='coral')\n",
    "    ax.set_yticks(x_pos)\n",
    "    ax.set_yticklabels(ranks['model'])\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Average Rank (lower is better)', fontsize=12)\n",
    "    ax.set_title('Model Ranking Based on Average Performance', fontsize=16, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, val) in enumerate(zip(bars, ranks['avg_rank'])):\n",
    "        ax.text(val + 0.05, i, f'{val:.2f}', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outdir / \"model_ranking.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. Box plot showing metric distribution\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    melted = summary_df.melt(id_vars='model', value_vars=metrics, \n",
    "                             var_name='Metric', value_name='Score')\n",
    "    sns.boxplot(data=melted, x='Metric', y='Score', ax=ax, palette='Set2')\n",
    "    sns.swarmplot(data=melted, x='Metric', y='Score', color='black', alpha=0.5, ax=ax)\n",
    "    ax.set_title('Distribution of Metrics Across All Models', fontsize=16, fontweight='bold')\n",
    "    ax.set_ylabel('Score', fontsize=12)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outdir / \"metrics_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"✓ Generated 5 comparison visualizations in {outdir}\")\n",
    "    print(\"  - metrics_comparison_bars.png\")\n",
    "    print(\"  - metrics_radar_chart.png\")\n",
    "    print(\"  - metrics_heatmap.png\")\n",
    "    print(\"  - model_ranking.png\")\n",
    "    print(\"  - metrics_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fe2a30",
   "metadata": {},
   "source": [
    "## MAIN RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89e745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Initialize logger first\n",
    "    setup_logger()\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"Starting Baseline Models Training Pipeline\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Print initial memory state\n",
    "    try:\n",
    "        print_memory_usage()\n",
    "    except Exception as e:\n",
    "        print(f\"[Memory] Could not print memory usage: {e}\")\n",
    "    \n",
    "    outdir = make_output_dir()\n",
    "    print(f\"Output directory: {outdir}\")\n",
    "\n",
    "    X, y, groups = load_data()\n",
    "    feature_names = X.columns.tolist()\n",
    "    n_features = X.shape[1]\n",
    "    le = LabelEncoder()\n",
    "    dump(le, outdir / \"label_encoder.joblib\")\n",
    "\n",
    "    y = le.fit_transform(y.astype(str))\n",
    "    num_classes = len(le.classes_)\n",
    "    # Save mapping for later interpretability\n",
    "    label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    print(f\"Label mapping: {label_map}\")\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "    ks = k_grid_from_dim(n_features)\n",
    "    print(f\"Feature selection grid: {ks}\")\n",
    "\n",
    "    # Train/holdout split:\n",
    "    if groups is not None:\n",
    "        print(\"Performing group-based train/test split...\")\n",
    "        # split by groups: keep some groups entirely in holdout\n",
    "        unique_g = pd.Series(groups).drop_duplicates()\n",
    "        holdout_frac = 0.2\n",
    "        n_hold = max(1, int(len(unique_g) * holdout_frac))\n",
    "        hold_groups = set(unique_g.sample(n_hold, random_state=RANDOM_STATE))\n",
    "        mask_hold = pd.Series(groups).isin(hold_groups).values\n",
    "        X_train, X_test = X.loc[~mask_hold], X.loc[mask_hold]\n",
    "        y_train, y_test = y[~mask_hold], y[mask_hold]\n",
    "        groups_train = pd.Series(groups)[~mask_hold].values\n",
    "        print(f\"Train set: {X_train.shape[0]} samples\")\n",
    "        print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "        \n",
    "        # Clean up intermediate variables\n",
    "        del unique_g, hold_groups, mask_hold\n",
    "    else:\n",
    "        print(\"Performing random train/test split...\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    "        )\n",
    "        groups_train = None\n",
    "        print(f\"Train set: {X_train.shape[0]} samples\")\n",
    "        print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "    \n",
    "    # Delete full dataset to free memory\n",
    "    del X, y, groups\n",
    "    gc.collect()\n",
    "\n",
    "    # Models to train\n",
    "    models = []\n",
    "\n",
    "    # --- Logistic Regression (elastic-net) ---\n",
    "    for sub_name, est, space in logistic_space():\n",
    "        pipe = build_pipeline(est, scale_for_model=True, n_features=n_features,\n",
    "                            scaler_type=\"standard\", impute=True)\n",
    "        models.append((f\"{sub_name}\", pipe, space))\n",
    "\n",
    "    # --- Random Forest (GPU if available) ---\n",
    "    if HAVE_CUML:\n",
    "        print(\"Using RAPIDS cuML Random Forest (GPU)\")\n",
    "        rf = cuRF(random_state=RANDOM_STATE, n_streams=4)\n",
    "        models.append((\n",
    "            \"RandomForest_GPU\",\n",
    "            build_pipeline(rf, scale_for_model=False, n_features=n_features,\n",
    "                        scaler_type=None, impute=True),\n",
    "            rf_space_gpu()\n",
    "        ))\n",
    "    else:\n",
    "        print(\"Using sklearn Random Forest (CPU)\")\n",
    "        rf = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
    "        models.append((\n",
    "            \"RandomForest_CPU\",\n",
    "            build_pipeline(rf, scale_for_model=False, n_features=n_features,\n",
    "                        scaler_type=None, impute=True),\n",
    "            rf_space()\n",
    "        ))\n",
    "\n",
    "    # --- XGBoost (GPU if available) ---\n",
    "    if HAVE_XGB:\n",
    "        device = \"cuda\" if HAVE_TORCH and torch.cuda.is_available() else \"cpu\"\n",
    "        tree_method = \"hist\" if device == \"cpu\" else \"gpu_hist\"\n",
    "        print(f\"Using XGBoost with {tree_method} on {device}\")\n",
    "        \n",
    "        xgb = XGBClassifier(\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=-1 if device == \"cpu\" else 1,\n",
    "            tree_method=tree_method,\n",
    "            device=device,\n",
    "            objective=\"multi:softprob\",\n",
    "        )\n",
    "        models.append((\n",
    "            f\"XGBoost_{device.upper()}\",\n",
    "            build_pipeline(xgb, scale_for_model=False, n_features=n_features,\n",
    "                        scaler_type=None, impute=False),\n",
    "            xgb_space()\n",
    "        ))\n",
    "\n",
    "    # --- k-NN (GPU if available) ---\n",
    "    if HAVE_CUML:\n",
    "        print(\"Using RAPIDS cuML KNN (GPU)\")\n",
    "        knn = cuKNN()\n",
    "        models.append((\n",
    "            \"KNN_GPU\",\n",
    "            build_pipeline(knn, scale_for_model=True, n_features=n_features,\n",
    "                        scaler_type=\"standard\", impute=True),\n",
    "            knn_space_gpu()\n",
    "        ))\n",
    "    else:\n",
    "        print(\"Using sklearn KNN (CPU)\")\n",
    "        knn = KNeighborsClassifier()\n",
    "        models.append((\n",
    "            \"KNN_CPU\",\n",
    "            build_pipeline(knn, scale_for_model=True, n_features=n_features,\n",
    "                        scaler_type=\"standard\", impute=True),\n",
    "            knn_space()\n",
    "        ))\n",
    "\n",
    "    # --- MLP (GPU if available) ---\n",
    "    if HAVE_TORCH and torch.cuda.is_available():\n",
    "        print(\"Using PyTorch MLP (GPU)\")\n",
    "        device = 'cuda'\n",
    "        mlp = NeuralNetClassifier(\n",
    "            module=TorchMLP,\n",
    "            module__input_dim=n_features,\n",
    "            module__hidden_dim=128,\n",
    "            module__num_classes=num_classes,\n",
    "            module__dropout=0.2,\n",
    "            max_epochs=100,\n",
    "            lr=1e-3,\n",
    "            batch_size=128,\n",
    "            iterator_train__shuffle=True,\n",
    "            device=device,\n",
    "            verbose=0,\n",
    "        )\n",
    "        models.append((\n",
    "            \"MLP_GPU\",\n",
    "            build_pipeline(mlp, scale_for_model=True, n_features=n_features,\n",
    "                        scaler_type=\"standard\", impute=True),\n",
    "            mlp_space_gpu(n_features, num_classes)\n",
    "        ))\n",
    "    else:\n",
    "        print(\"Using sklearn MLP (CPU)\")\n",
    "        mlp = MLPClassifier(\n",
    "            early_stopping=True,\n",
    "            max_iter=400,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        models.append((\n",
    "            \"MLP_CPU\",\n",
    "            build_pipeline(mlp, scale_for_model=True, n_features=n_features,\n",
    "                        scaler_type=\"standard\", impute=True),\n",
    "            mlp_space()\n",
    "        ))\n",
    "\n",
    "    # --- SVC (GPU if available) ---\n",
    "    if HAVE_CUML:\n",
    "        print(\"Using RAPIDS cuML SVC (GPU)\")\n",
    "        svc = cuSVC(\n",
    "            kernel=\"rbf\",\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        models.append((\n",
    "            \"SVC_GPU\",\n",
    "            build_pipeline(\n",
    "                svc,\n",
    "                scale_for_model=True,\n",
    "                n_features=n_features,\n",
    "                scaler_type=\"standard\",\n",
    "                impute=True\n",
    "            ),\n",
    "            svc_space_gpu()\n",
    "        ))\n",
    "    else:\n",
    "        print(\"Using sklearn SVC (CPU)\")\n",
    "        svc = SVC(\n",
    "            kernel=\"rbf\",\n",
    "            probability=False,\n",
    "            decision_function_shape=\"ovr\",\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        models.append((\n",
    "            \"SVC_CPU\",\n",
    "            build_pipeline(\n",
    "                svc,\n",
    "                scale_for_model=True,\n",
    "                n_features=n_features,\n",
    "                scaler_type=\"standard\",\n",
    "                impute=True\n",
    "            ),\n",
    "            svc_space_classifier()\n",
    "        ))\n",
    "\n",
    "    print(f\"\\nTotal models to train: {len(models)}\")\n",
    "    summary = []\n",
    "\n",
    "    for idx, (name, pipe, space) in enumerate(models):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"=== Tuning {name} ({idx+1}/{len(models)}) ===\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Print memory before training\n",
    "        try:\n",
    "            print_memory_usage()\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        start_time = time.time()\n",
    "        best = search_cv_for_model(\n",
    "            name=name,\n",
    "            pipe=pipe,\n",
    "            param_space=space,\n",
    "            ks=ks,\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            groups=groups_train,\n",
    "            outdir=outdir,\n",
    "            n_iter=60 if HAVE_BAYES else 80\n",
    "        )\n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        metrics = evaluate_on_holdout(best, X_test, y_test, outdir / name, label=f\"{name}_holdout\")\n",
    "        print(f\"{name} holdout metrics: {metrics}\")\n",
    "        print(f\"Training time: {elapsed:.2f} seconds\")\n",
    "        \n",
    "        row = {\"model\": name, **metrics, \"training_time_sec\": elapsed}\n",
    "        summary.append(row)\n",
    "        \n",
    "        # Explicit cleanup after each model\n",
    "        del best, pipe, space\n",
    "        cleanup_memory()\n",
    "        \n",
    "        # Print memory after cleanup\n",
    "        try:\n",
    "            print(f\"[Memory] Cleaned up after {name}\")\n",
    "            print_memory_usage()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Clean up models list\n",
    "    del models\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"Saving results and generating visualizations...\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary)\n",
    "    summary_df.to_csv(outdir / \"holdout_summary.csv\", index=False)\n",
    "    create_comparison_visualizations(summary_df, outdir)\n",
    "    \n",
    "    with open(outdir / \"env_info.json\", \"w\") as f:\n",
    "        json.dump({\n",
    "            \"HAVE_BAYES\": HAVE_BAYES,\n",
    "            \"HAVE_XGB\": HAVE_XGB,\n",
    "            \"HAVE_TORCH\": HAVE_TORCH,\n",
    "            \"HAVE_CUML\": HAVE_CUML,\n",
    "            \"random_state\": RANDOM_STATE,\n",
    "            \"n_features\": n_features,\n",
    "            \"num_classes\": num_classes,\n",
    "            \"ks\": ks,\n",
    "            \"versions\": {\n",
    "                \"pandas\": pd.__version__,\n",
    "                \"numpy\": np.__version__,\n",
    "            }\n",
    "        }, f, indent=2)\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"=== Training Pipeline Complete ===\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Results saved to: {outdir}\")\n",
    "    print(f\"Log file saved in: logs/\")\n",
    "    \n",
    "    # Final memory state\n",
    "    try:\n",
    "        print(\"\\n[Memory] Final state:\")\n",
    "        print_memory_usage()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     print_device_info()\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d9cf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]C:\\Users\\Kadri.Mufti\\AppData\\Local\\Temp\\ipykernel_43572\\1111364072.py:11: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp = pd.read_csv(path)\n",
      " 17%|█▋        | 1/6 [00:08<00:41,  8.33s/it]C:\\Users\\Kadri.Mufti\\AppData\\Local\\Temp\\ipykernel_43572\\1111364072.py:11: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp = pd.read_csv(path)\n",
      " 33%|███▎      | 2/6 [00:25<00:53, 13.29s/it]C:\\Users\\Kadri.Mufti\\AppData\\Local\\Temp\\ipykernel_43572\\1111364072.py:11: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp = pd.read_csv(path)\n",
      " 50%|█████     | 3/6 [00:40<00:42, 14.14s/it]C:\\Users\\Kadri.Mufti\\AppData\\Local\\Temp\\ipykernel_43572\\1111364072.py:11: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp = pd.read_csv(path)\n",
      " 67%|██████▋   | 4/6 [00:53<00:27, 13.79s/it]C:\\Users\\Kadri.Mufti\\AppData\\Local\\Temp\\ipykernel_43572\\1111364072.py:11: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp = pd.read_csv(path)\n",
      " 83%|████████▎ | 5/6 [00:59<00:10, 10.98s/it]C:\\Users\\Kadri.Mufti\\AppData\\Local\\Temp\\ipykernel_43572\\1111364072.py:11: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp = pd.read_csv(path)\n",
      "100%|██████████| 6/6 [01:00<00:00, 10.15s/it]\n",
      "C:\\Users\\Kadri.Mufti\\AppData\\Local\\Temp\\ipykernel_43572\\1111364072.py:29: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  groups = df[\"Timestamp\"].dt.floor(\"1T\")  # group by minute\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.str_('0'): np.int64(0), np.str_('1'): np.int64(1), np.str_('2'): np.int64(2), np.str_('3'): np.int64(3), np.str_('4'): np.int64(4), np.str_('5'): np.int64(5), np.str_('6'): np.int64(6), np.str_('7'): np.int64(7)}\n",
      "\n",
      "=== Tuning LogisticRegression ===\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 6.59 GiB for an array with shape (82, 10793113) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_RemoteTraceback\u001b[39m                          Traceback (most recent call last)",
      "\u001b[31m_RemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 490, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\joblib\\parallel.py\", line 607, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\joblib\\parallel.py\", line 607, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 147, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\sklearn\\pipeline.py\", line 655, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\sklearn\\pipeline.py\", line 589, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\joblib\\memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1540, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\sklearn\\pipeline.py\", line 719, in fit_transform\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\sklearn\\pipeline.py\", line 589, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\joblib\\memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1540, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\sklearn\\base.py\", line 897, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\sklearn\\impute\\_base.py\", line 452, in fit\n    X = self._validate_input(X, in_fit=True)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\sklearn\\impute\\_base.py\", line 360, in _validate_input\n    X = validate_data(\n        ^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2954, in validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2165, in __array__\n    values = self._values\n             ^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\pandas\\core\\frame.py\", line 1127, in _values\n    return ensure_wrapped_if_datetimelike(self.values)\n                                          ^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\pandas\\core\\frame.py\", line 12671, in values\n    return self._mgr.as_array()\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1694, in as_array\n    arr = self._interleave(dtype=dtype, na_value=na_value)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1727, in _interleave\n    result = np.empty(self.shape, dtype=dtype)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nnumpy._core._exceptions._ArrayMemoryError: Unable to allocate 6.59 GiB for an array with shape (82, 10793113) and data type object\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 115\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, pipe, space \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[32m    114\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Tuning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     best = \u001b[43msearch_cv_for_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparam_space\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m        \u001b[49m\u001b[43mks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutdir\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mHAVE_BAYES\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m80\u001b[39;49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m     metrics = evaluate_on_holdout(best, X_test, y_test, outdir / name, label=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_holdout\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m holdout metrics:\u001b[39m\u001b[33m\"\u001b[39m, metrics)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36msearch_cv_for_model\u001b[39m\u001b[34m(name, pipe, param_space, ks, X, y, groups, outdir, n_iter)\u001b[39m\n\u001b[32m     24\u001b[39m         cv_groups = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     25\u001b[39m     search = BayesSearchCV(\n\u001b[32m     26\u001b[39m         estimator=pipe,\n\u001b[32m     27\u001b[39m         search_spaces=param_space,\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m         verbose=\u001b[32m0\u001b[39m,\n\u001b[32m     35\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[43msearch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgroups\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_groups\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv_groups\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     38\u001b[39m     \u001b[38;5;66;03m# Randomized search\u001b[39;00m\n\u001b[32m     39\u001b[39m     param_dist = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\skopt\\searchcv.py:542\u001b[39m, in \u001b[36mBayesSearchCV.fit\u001b[39m\u001b[34m(self, X, y, groups, callback, **fit_params)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.refit):\n\u001b[32m    536\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    537\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mBayesSearchCV doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt support a callable refit, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    538\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt define an implicit score to \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    539\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33moptimize\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    540\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m542\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[38;5;66;03m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[32m    545\u001b[39m \u001b[38;5;66;03m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_train_score:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\skopt\\searchcv.py:599\u001b[39m, in \u001b[36mBayesSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m n_iter > \u001b[32m0\u001b[39m:\n\u001b[32m    596\u001b[39m     \u001b[38;5;66;03m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[32m    597\u001b[39m     n_points_adjusted = \u001b[38;5;28mmin\u001b[39m(n_iter, n_points)\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     optim_result, score_name = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m        \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_points\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_points_adjusted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    606\u001b[39m     n_iter -= n_points\n\u001b[32m    608\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\skopt\\searchcv.py:453\u001b[39m, in \u001b[36mBayesSearchCV._step\u001b[39m\u001b[34m(self, search_space, optimizer, score_name, evaluate_candidates, n_points)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;66;03m# make lists into dictionaries\u001b[39;00m\n\u001b[32m    451\u001b[39m params_dict = [point_asdict(search_space, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m all_results = \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[38;5;66;03m# if self.scoring is a callable, we have to wait until here\u001b[39;00m\n\u001b[32m    456\u001b[39m \u001b[38;5;66;03m# to get the score name\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m score_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\joblib\\parallel.py:1784\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1779\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1780\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1781\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1782\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1783\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1785\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1787\u001b[39m     nb_jobs = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\joblib\\parallel.py:1859\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1855\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1856\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1857\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1859\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\joblib\\parallel.py:758\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    752\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    755\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    757\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kadri.Mufti\\Desktop\\CS8001\\introml_labs\\Lib\\site-packages\\joblib\\parallel.py:773\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 6.59 GiB for an array with shape (82, 10793113) and data type object"
     ]
    }
   ],
   "source": [
    "print_device_info()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1695056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c56864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "introml_labs (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
